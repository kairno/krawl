<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level</title>
				<funder ref="#_yvASUxQ">
					<orgName type="full">European Research Council</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministry of Science and Technology (MOST) of the Israeli Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.87,123.56,54.71,10.75"><forename type="first">Amit</forename><surname>Seker</surname></persName>
							<email>aseker00@gmail.com</email>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.74,123.56,65.32,10.75"><forename type="first">Elron</forename><surname>Bandel</surname></persName>
							<email>elronbandel@gmail.com</email>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,287.60,123.56,62.01,10.75"><forename type="first">Dan</forename><surname>Bareket</surname></persName>
							<email>dbareket@gmail.com</email>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.99,123.56,84.20,10.75"><forename type="first">Idan</forename><surname>Brusilovsky</surname></persName>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.86,137.51,73.28,10.75"><forename type="first">Shaked</forename><surname>Refael</surname></persName>
							<email>shakedgreenfeld@gmail.com</email>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.13,137.51,81.47,10.75"><forename type="first">Reut</forename><surname>Greenfeld</surname></persName>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.58,137.51,43.83,10.75"><surname>Tsarfaty</surname></persName>
							<email>reut.tsarfaty@gmail.com</email>
							<affiliation key="aff0" coords="1,123.62,151.92,351.03,10.37">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7FAF86FEFDE4C39CD15C42AE94C145CA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-05-21T00:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[affiliation, biblStruct, figure, formula, head, note, persName, ref, s], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Pre-trained Language Models (PLMs) have become ubiquitous in the development of language understanding technology and lie at the heart of many artificial intelligence advances. While advances reported for English using PLMs are unprecedented, reported advances using PLMs for Hebrew are few and far between. The problem is twofold. First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts. Second, most benchmarks available to evaluate progress in Hebrew NLP require morphological boundaries which are not available in the output of PLMs. In this work we remedy both aspects. We present AlephBERT, a large PLM for Modern Hebrew, trained on larger vocabulary and a larger dataset than any Hebrew PLM before. Moreover, we introduce a novel neural architecture that recovers the morphological segments encoded in contextualized embedding vectors. Based on this new morphological component we offer an evaluation suite consisting of multiple tasks and benchmarks that cover sentencelevel, word-level and sub-word level analyses. On all tasks, AlephBERT obtains state-of-theart results beyond contemporary Hebrew stateof-the-art models. We make our AlephBERT model, the morphological extraction component, and the Hebrew evaluation suite publicly available, for future investigations and evaluations of Hebrew PLMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" coords="1,70.86,620.90,82.82,10.75">Introduction</head><p>Contextualized word representations provided by models such as BERT <ref type="bibr" coords="1,186.71,655.54,99.00,9.46" target="#b8">(Devlin et al., 2019)</ref>, RoBERTa <ref type="bibr" coords="1,118.61,669.09,73.48,9.46" target="#b12">(Liu et al., 2019)</ref>, GPT3 <ref type="bibr" coords="1,229.33,669.09,61.17,9.46;1,70.86,682.64,23.95,9.46" target="#b6">(Brown et al., 2020)</ref>, T5 <ref type="bibr" coords="1,120.91,682.64,91.66,9.46" target="#b19">(Raffel et al., 2020)</ref> and more, were shown in recent years to be a critical component for obtaining state-of-the-art performance on a wide range of Natural Language Processing (NLP) tasks, from surface syntactic tasks as tagging and parsing, to downstream semantic tasks as question answering, information extraction and text summarization.</p><p>While advances reported for English using such models are unprecedented, previously reported results using PLMs in Modern Hebrew are far from satisfactory. Specifically, the BERT-based Hebrew section of multilingual-BERT <ref type="bibr" coords="1,437.76,270.64,87.39,9.46" target="#b8">(Devlin et al., 2019)</ref> (henceforth, mBERT), did not provide a similar boost in performance as observed by the English section of mBERT. In fact, for several reported tasks, the results of the mBERT model are on a par with pre-neural models or neural models based on non-contextual embeddings <ref type="bibr" coords="1,430.54,351.94,94.78,9.46" target="#b27">(Tsarfaty et al., 2020;</ref><ref type="bibr" coords="1,306.14,365.49,107.54,9.46" target="#b11">Klein and Tsarfaty, 2020</ref>). An additional Hebrew <ref type="bibr" coords="1,306.14,379.04,219.64,9.46;1,306.14,392.59,23.53,9.46">BERT-based model, HeBERT (Chriqui and Yahav, 2021)</ref>, has been recently released, yet without empirical evidence of performance improvements on key components of the Hebrew NLP pipeline.</p><p>The challenge of developing PLMs for morphologically-rich and medium-resourced languages such as Modern Hebrew is twofold. First, contextualized word representations are obtained by pre-training a large language model on massive quantities of unlabeled texts. In Hebrew, the size of published texts available for training is relatively small. To wit, Hebrew Wikipedia (300K articles) used for training mBERT is orders of magnitude smaller compared to English Wikipedia (6M articles). Second, commonly accepted benchmarks for evaluating Hebrew models, via Morpho-Syntactic Tagging and Parsing <ref type="bibr" coords="1,394.88,597.39,80.44,9.46" target="#b22">(Sadde et al., 2018)</ref>, or Named Entity Recognition <ref type="bibr" coords="1,394.72,610.94,130.43,9.46" target="#b3">(Bareket and Tsarfaty, 2020)</ref> require decomposition of words into morphemes,<ref type="foot" coords="1,520.54,622.44,3.99,6.91" target="#foot_0">foot_0</ref> which are distinct of the sub-words (a.k.a. wordpieces) provided by standard PLMs. Such morphemes are as of yet not readily available in the PLMs' output embeddings.</p><p>Evaluating BERT-based models on morphemelevel tasks is thus non-trivial due to the mismatch between the sub-word tokens used as sub-word Figure <ref type="figure" coords="2,98.93,212.30,3.81,8.64">1</ref>: PLM Morphological Extraction Pipeline. The two-word phrase " ‫הלב‬ ‫,"לבית‬ transliterated as "lbit hlbn", mapped to word-pieces which are consumed by a PLM to generate contextualized vectors and extract the sub-word morphological units. In this example the WordPiece Tokenizer splits the first word, "lbit", into two pieces while leaving the second word, "hlbn", intact. Consequently, AlephBERT generates 3 embedded vectors -the vectors associated with the split word pieces are averaged to form a single contextualized vector. Finally, the resulting two word vectors are used by the Morphological Extraction Model that generates the disambiguated morphological segments.</p><p>input units used by the PLMs and the sub-word morphological units needed for evaluation. PLMs employ sub-word tokenization mechanisms such as WordPiece or Byte-Pair Encoding (BPE) for the purposes of minimizing Out-Of-Vocabulary words <ref type="bibr" coords="2,70.50,457.39,94.52,9.46" target="#b26">(Sennrich et al., 2016)</ref>. These sub-word tokens are generated in a pre-processing step, without utilization of any linguistic information, and passed as input to the PLM. Crucially, such word-pieces do not reflect morphological units. Extracting morphological units from contextualized vectors provided by PLMs is challenging yet necessary in order to enable morphological-level evaluation of Hebrew PLMs on standard benchmarks.</p><p>In this paper we introduce AlephBERT, a Hebrew PLM trained on more data and a larger vocabulary than any Hebrew PLM before.<ref type="foot" coords="2,202.39,604.39,3.99,6.91" target="#foot_2">foot_2</ref> Moreover, we propose a novel architecture that extracts the morphological sub-word units implicitly encoded in the contextualized vectors outputted by PLMs. Using AlephBERT and the proposed morphological extraction model we enable evaluation on all existing Hebrew benchmarks. We thus present a processing and evaluation pipeline tailored to fit Morphologically Rich Languages (MRLs), i.e., covering sentence-level, word-level and most importantly sub-word morphological-level tasks (Segmentation, Part-of-Speech Tagging, full Morphological Tagging, Dependency Parsing, Named Entity Recognition (NER) and Sentiment Analysis), and present new and improved SOTA for Modern Hebrew on all of these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" coords="2,306.14,178.75,94.02,10.75">Previous Work</head><p>Contextualized word embedding vectors are a major driver for improved performance of deep learning models on many Natural Language Understanding (NLU) tasks. Initially, ELMo <ref type="bibr" coords="2,465.32,241.55,60.47,9.46;2,306.14,255.10,25.76,9.46" target="#b16">(Peters et al., 2018)</ref> and ULMFit <ref type="bibr" coords="2,392.80,255.10,118.45,9.46" target="#b10">(Howard and Ruder, 2018)</ref>  BERT Benchmarks An integral part involved in developing various PLMs is providing NLU multitask benchmarks used to demonstrate the linguistic abilities of new models and approaches. English BERT models are evaluated on 3 standard major benchmarks. The Stanford Question Answering Dataset (SQuAD) <ref type="bibr" coords="2,387.83,628.44,103.48,9.46" target="#b20">(Rajpurkar et al., 2016)</ref> is used for testing paragraph-level reading comprehension abilities. <ref type="bibr" coords="2,346.61,655.54,80.54,9.46" target="#b29">Wang et al. (2018)</ref> selected a diverse and relatively hard set of sentence and sentence-pair tasks which comprise the General Language Understanding Evaluation (GLUE) benchmark. The SWAG (Situations With Adversarial Generations) dataset <ref type="bibr" coords="2,339.42,723.29,89.44,9.46" target="#b31">(Zellers et al., 2018)</ref> presents models with partial description of grounded situations to see if they can consistently predict subsequent scenarios, thus indicating abilities of commonsense reasoning.</p><p>When evaluating Hebrew PLMs, one of the key pitfalls is that there are no Hebrew versions for these benchmarks. Furthermore, none of the suggested benchmarks account for examining the capacity of PLMs for encoding the word-internal morphological structures which are inherent in MRLs. In this work we enable a generic morphological-level evaluation pipeline that is suited for PLMs of MRLs.</p><p>Multilingual vs. Monolingual <ref type="bibr" coords="3,218.34,195.32,70.79,9.88;3,70.86,209.30,56.64,9.46">BERT Devlin et al. (2019)</ref> produced 2 BERT models, for English and Chinese. To support other languages, they trained a multilingual BERT (mBERT) model combining texts covering over 100 languages, in the hoped to benefit low-resource languages with the linguistic information obtained from languages with larger datasets. In reality, however, mBERT performance on specific languages has not been as successful as English. Consequently, several research efforts focused on building monolingual BERT models as well as providing languagespecific evaluation benchmarks. <ref type="bibr" coords="3,217.09,358.35,72.78,9.46" target="#b12">Liu et al. (2019)</ref> trained CamemBERT, a French BERT model evaluated on syntactic and semantic tasks in addition to natural language inference tasks. <ref type="bibr" coords="3,236.27,399.00,54.77,9.46;3,70.50,412.54,29.00,9.46" target="#b21">Rybak et al. (2020)</ref> trained HerBERT, a BERT PLM for Polish. They evaluated it on a diverse set of existing NLU benchmarks as well as a new dataset for sentiment analysis for the e-commerce domain. <ref type="bibr" coords="3,244.01,453.19,45.13,9.46;3,70.86,466.74,55.35,9.46" target="#b17">Polignano et al. (2019)</ref> created Alberto, a BERT model for Italian, using a massive tweet collection. They tested it on several NLU tasks -subjectivity, polarity (sentiment) and irony detection in tweets. In order to obtain a large enough training corpus in low-resources languages, such as Finnish <ref type="bibr" coords="3,248.82,534.49,40.32,9.46;3,70.86,548.04,52.92,9.46" target="#b28">(Virtanen et al., 2019)</ref> and Persian <ref type="bibr" coords="3,180.68,548.04,96.02,9.46" target="#b9">(Farahani et al., 2020)</ref>, a great deal of effort went into filtering and cleaning text samples obtained from web crawls.</p><p>BERT for MRLs Languages with rich morphology introduce another challenge involving the identification and extraction of sub-word morphological information. In many MRLs words are composed of sub-word morphological units, with each unit acting as a single syntactic unit bearing as single POS tag (mimicking 'words' in English). <ref type="bibr" coords="3,256.04,682.64,33.09,9.46;3,70.86,696.19,54.70,9.46" target="#b1">Antoun et al. (2020)</ref> addressed this for Arabic, a Semitic MRLs, by pre-processing the training data using a morphological segmenter, producing morphological segments to be used for training AraBERT instead of the actual words. By doing so, they were able to produce output vectors that corre- spond to morphological segments rather than the original space-delimited word-tokens. However, this approach requires the application of the same segmenter at inference time as well, and like any pipeline approach, this setup is susceptible to error propagation. This risk is magnified as words in MRLs may be morphologically ambiguous, and the predicted segments might not represent the correct interpretation of the words. As a result, the quality of the PLM depends on the accuracy achieved by the segmenting component. A particular novelty of this work is not making any changes to the input, letting the PLM encode morphological information associated with complete Hebrew tokens. Instead, transforming the resulting contextualized word vectors into morphological-level segments via a novel neural architecture which we discuss shortly.</p><p>Evaluating PLMs for MRLs Across all of the above-mentioned language-specific PLMs, evaluation was performed on the word-,sentence-or paragraph-level.  <ref type="bibr" coords="4,70.86,298.68,53.29,9.46">et al., 2020)</ref>. (ii) Wikipedia: Texts from all of Hebrew Wikipedia, extracted using <ref type="bibr" coords="4,226.09,312.23,60.45,9.46" target="#b2">Attardi (2015)</ref>.</p><p>(iii) Twitter: Hebrew tweets collected between 2014-09-28 and 2018-03-07. We removed markers ("RT:", "@" user mentions and URLs), and eliminated duplicates. For data statistics, see Table <ref type="table" coords="4,272.58,366.43,4.09,9.46" target="#tab_1">2</ref>. The Hebrew portions of Oscar and Wikipedia provide us with a training-set size orders-ofmagnitude smaller compared with resource-savvy languages, as shown in Table <ref type="table" coords="4,203.98,421.24,4.17,9.46" target="#tab_0">1</ref>. In order to build a strong PLM we need a considerable boost in the amount of sentences the PLM can learn from, which in our case comes form massive amounts of tweets added to the training set. We acknowledge the potential inherent concerns associated with this data source (population bias, behavior patterns, bot masquerading as humans etc.) and note that we have not made any explicit attempt to identify these cases. Honoring ethical and legal constraints we have not manually analyzed nor published this data source. While the free form language expressed in tweets might differ significantly from the text found in Oscar and Wikipedia, the sheer volume of tweets helps us close the resource gap substantially with minimal effort. 3   Model We used the Transformers training framework of Huggingface <ref type="bibr" coords="4,162.83,661.04,76.86,9.46" target="#b30">(Wolf et al., 2020)</ref> and trained two different models -a small model with 6 hidden layers learned from the Oscar portion of our dataset, and a base model with 12 hidden layers which was trained on the entire dataset. The processing units used are wordpieces generated by training BERT tokenizers over the respective 3 For more details and an ethical discussion, see Section 8. datasets with a vocabulary size of 52K in both cases. Following the work on RoBERTa <ref type="bibr" coords="4,452.54,88.25,72.61,9.46" target="#b12">(Liu et al., 2019)</ref> we optimize AlephBERT with a masked-token prediction loss. We deploy the default masking configuration where 15% of word piece tokens are masked. In 80% of the cases, they are replaced by <ref type="bibr" coords="4,306.14,156.00,36.29,9.46">[MASK]</ref>, in 10% of the cases, they are replaced by a random token and in the remaining cases, the masked tokens are left as is.</p><p>Operation To optimize GPU utilization and decrease training time we split the dataset into 4 chunks based on the number of tokens in a sentence and consequently we are able to increase batch sizes and dramatically shorten training time.</p><formula xml:id="formula_0" coords="4,313.12,280.48,204.33,29.94">chunk1 chunk2 chunk3 chunk4 max tokens 0&gt;32 32&gt;64 64&gt;128 128&gt;512 num sentences 70M 20M 5M 2M</formula><p>We trained for 5 epochs with learning rate 1e-4 followed by an additional 5 epochs with learning rate at 5e-5 for a total of 10 epochs. We trained AlephBERT base over the entire dataset on an NVidia DGX server with 8 V100 GPUs which took 8 days. AlephBERT small was trained over the Oscar portion only, using 4 GTX 2080ti GPUs taking 5 days in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" coords="4,306.14,444.23,208.77,10.75">The Morphological Extraction Model</head><p>Modern Hebrew is a Semitic language with rich morphology and complex orthography. As a result, the basic processing units in the language are typically smaller than raw space-delimited tokens. Subsequently, most standard evaluation tasks require knowledge of the internal morphological boundaries within the raw tokens. To accommodate this granularity requirement we developed a neural model designed to produce the disambiguated morphological segments for each token in context. These linguistic segmentations are distinct of the word-pieces employed by the PLM.</p><p>In the morphological extraction neural model, each input token is represented by (one or more) contextualized word-vectors produced by the PLM. Each word-piece token is associated with a vector, and for each space-delimited token, we average the word-piece vectors. We feed the resulting vector into a seq2seq model and encode the surface token as a sequence of characters using a BiLSTM, followed by a decoder that generates an output sequence of characters, using space as a special symbol signaling morphological boundaries.  The embedded vectors associated with the wordpieces (v1 and v2 representing word-piece vectors genin Figure <ref type="figure" coords="5,135.97,416.49,4.12,8.64">1</ref>) are combined (averaged) to produce a single word context vector. This context vector initializes the hidden (forward and backward) state of a BiLSTM that encodes the characters of the origin word. The decoder LSTM outputs a sequence of characters, where a special empty symbol indicates a morphological segment boundary. In multi-task setup, a fully connected linear layer is used to predict a label whenever a segment boundary is detected.</p><p>For tasks involving both segments and labels (Part-of-Speech Tagging, Morphological-Features Tagging, Named-Entity Recognition) we expand this network in a multi-task learning setup; when generating an end-of-segment (space) symbol, the model also predicts task label, and we combine the segment-label losses. The complete morphological extraction architecture is illustrated in Figure <ref type="figure" coords="5,270.07,643.53,4.09,9.46" target="#fig_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" coords="5,70.86,670.80,119.89,10.75">Experimental Setup</head><p>Goal In order to empirically gauge the effect of model size and data quantity on the quality of the language model, we compare the performance of AlephBERT (both small and base) with all existing Hebrew BERT instantiations. In this Section, we detail the tasks and evaluation metrics. In the next Section, we present and analyze the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1" coords="5,306.14,266.86,144.25,9.81">Sentence-Based Modeling</head><p>Sentiment Analysis We first report on a sentence classification task, assigning a sentence with one of three sentiment values: negative, positive, neutral. Sentence-level predictions are achieved by directly fine-tuning the PLM using an additional sentenceclassification head The sentence-level embedding vector representation is the one associated with the special [CLS] BERT token.</p><p>We used a version of the Hebrew Facebook Sentiment dataset (henceforth FB) of <ref type="bibr" coords="5,464.88,408.32,61.45,9.46;5,305.78,421.87,29.67,9.46" target="#b0">Amram et al. (2018)</ref> which we corrected by removing leaked samples. <ref type="foot" coords="5,344.29,433.37,3.99,6.91" target="#foot_3">4</ref> We fine-tuned all models for 15 epochs with 5 different seeds, and report mean accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2" coords="5,306.14,472.80,129.50,9.81">Word-Based Modeling</head><p>Named Entity Recognition In this setup we assume a sequence labeling task based on spacedelimited word-tokens. The input comprises of the sequence of words in the sentence, and the output contains BIOES tags indicating entity spans. Word-level NER predictions are achieved by directly fine-tuning the PLMs using an additional token-classification head In cases where a word is split into multiple word pieces by the PLM tokenizer, we employ common practice and use the first word-piece vector.</p><p>We evaluate this model on two corpora. (i) The Ben-Mordecai (BMC) corpus <ref type="bibr" coords="5,439.32,654.91,85.10,9.46;5,306.14,668.46,67.35,9.46" target="#b4">(Ben Mordecai and Elhadad, 2005)</ref>, which contains 3294 sentences with 4600 entities and seven different entity categories (Date, Location, Money, Organization, Person, Percent, Time). To remain compatible with the original work we train and test the models on 3 different splits as in <ref type="bibr" coords="6,162.17,74.70,124.24,9.46" target="#b3">Bareket and Tsarfaty (2020)</ref>. (ii) The Named Entities and MOrphology (NEMO) corpus<ref type="foot" coords="6,100.52,99.76,3.99,6.91" target="#foot_4">foot_4</ref>  <ref type="bibr" coords="6,107.72,101.80,128.14,9.46" target="#b3">(Bareket and Tsarfaty, 2020)</ref> which is an extension of the SPMRL dataset with Named Entities. The NEMO corpus contains 6220 sentences with 7713 entities of nine entity types (Language, Product, Event, Facility, Geo-Political Entity, Location, Organization, Person, Work-Of-Art). We trained both models for 15 epochs with 5 different seeds and report mean F1 scores on entity spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3" coords="6,70.86,219.52,154.44,9.81">Morpheme-Based Modeling</head><p>Finally, to probe the PLM capacity to accurately predict word-internal structure, we test all models on five tasks that require knowledge of the internal morphology of raw words. The input to all these tasks is a Hebrew sentence represented as a raw sequence of space-delimited words:</p><p>(i) Segmentation: Generating a sequence of morphological segments representing the basic processing units. These units comply with the 2-level representation of tokens defined by UD, each unit with a single POS tag.<ref type="foot" coords="6,253.58,381.41,3.99,6.91" target="#foot_5">foot_5</ref> (ii) Part-of-Speech (POS) Tagging: Tagging each segment with a single POS. (iii) Morphological Tagging: Tagging each segment with a single POS and a set of features. Equivalent to the AllTags evaluation defined in the CoNLL18 shared task.<ref type="foot" coords="6,253.88,462.71,3.99,6.91" target="#foot_6">foot_6</ref> (iv) Morpheme-Based NER: Tagging each segment with a BIOES and its entity-type. (v) Dependency Parsing: Use each segment as a node in the predicted dependency tree.</p><p>We train and test all morphologically-aware models using two available morphologically-aware Hebrew resources:</p><p>• The Hebrew Section of the SPMRL Task <ref type="bibr" coords="6,267.79,593.19,18.53,9.46;6,92.68,606.74,68.63,9.46" target="#b24">(Seddah et al., 2013)</ref>.</p><p>• The Hebrew Section of the UD treebanks collection <ref type="bibr" coords="6,125.10,643.85,85.14,9.46" target="#b22">(Sadde et al., 2018)</ref> All models were trained for 15 epochs with 5 different seeds and we report two variants of mean F1 scores as described next.</p><p>For tasks (i)-(iv) we use the morphological extraction model (Section 4) to extract the morphological segments of each word in context and also predict the labels via Multitask training.</p><p>For task (iv) the NER task, we use the morphologically-annotated data files of the aforementioned SPMRL-based NEMO corpus <ref type="bibr" coords="6,487.27,156.63,37.15,9.46;6,306.14,170.18,85.47,9.46" target="#b3">(Bareket and Tsarfaty, 2020)</ref>. In addition to the multi-task setup described earlier, we design another setup in which we first only segment the text, and then perform fine-tuning with a token classification attention head directly applied to the PLM output for the segmented tokens (similar to the way we fine-tune the PLM for the word-based NER task described in the previous section). We acknowledge that we are fine-tuning the PLM on morphological segments the model was not originally pre-trained on, however, as we shall see shortly, this seemingly unintuitive strategy performs surprisingly well.</p><p>For task (v) we set up a dependency parsing evaluation pipeline using the standalone Hebrew parser offered by More et al. ( <ref type="formula" coords="6,444.34,360.51,19.78,9.46">2019</ref>) (a.k.a YAP) which was trained to produce SPMRL dependency labels. The morphological information for each word (namely the segments and POS tags) is recovered by our morphological extraction model, and is used as input features for the YAP standalone dependency parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4" coords="6,306.14,465.95,199.47,9.81">Morpheme-Based Evaluation Metrics</head><p>Aligned Segment The CoNLL18 Shared Task evaluation campaign<ref type="foot" coords="6,398.68,496.61,3.99,6.91" target="#foot_7">foot_7</ref> reports scores for segmentation and POS tagging<ref type="foot" coords="6,411.10,510.16,3.99,6.91" target="#foot_8">foot_8</ref> for all participating languages. For multi-segment words, the gold and predicted segments are aligned by their Longest Common Sub-sequence, and only matching segments are counted as true positives. We use the script to compare aligned segment and tagging scores between oracle (gold) segmentation and realistic (predicted) segmentation.</p><p>Aligned Multi-Set In addition to the CoNLL18 metrics, we compute F1 scores, with a slight but important difference from the shared task, as defined by <ref type="bibr" coords="6,343.95,670.80,78.56,9.46" target="#b14">More et al. (2019)</ref> and <ref type="bibr" coords="6,443.53,670.80,81.27,9.46;6,305.78,684.35,27.54,9.46" target="#b25">Seker and Tsarfaty (2020)</ref>. For each word, counts are based on multiset intersections of the gold and predicted labels ignoring the order of the segments while account-  <ref type="bibr" coords="7,241.16,188.89,47.98,8.64;7,70.55,200.85,62.20,8.64" target="#b3">Bareket and Tsarfaty (2020)</ref>. Sentiment Analysis accuracy on the corrected version of the corpus of <ref type="bibr" coords="7,206.04,212.80,78.90,8.64" target="#b0">Amram et al. (2018)</ref>.</p><p>ing for the number of each segment. Aligned mset is based on set difference which acknowledges the possible undercover of covert morphemes which is an appropriate measure of morphological accuracy.</p><p>Discussion To illustrate the difference between aligned segment and aligned mset, let us take for example the gold segmented tag sequence: b/IN, h/DET, bit/NOUN and the predicted segmented tag sequence b/IN, bit/NOUN. According to aligned segment, the first segment (b/IN) is aligned and counted as a true positive, the second segment however is considered as a false positive (bit/NOUN) and false negative (h/DET) while the third gold segment is also counted as a false negative (bit/NOUN).</p><p>On the other hand with aligned multi-set both b/IN and bit/NOUN exist in the gold and predicted sets and counted as true positives, while h/DET is mismatched and counted as a false negative. In both cased the total counts across words in the entire datasets are incremented accordingly and finally used for computing Precision, Recall and F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" coords="7,70.86,549.28,55.13,10.75">Results</head><p>Sentence-Level Task Sentiment analysis accuracy results are provided in Table 6: Morpheme-Based Aligned MultiSet (mset) F1 results on the UD corpus. Previous SOTA reported by Seker and Tsarfaty (2020) (POS)</p><p>word (segment-level) information. Specifically, we evaluate word segmentation, POS, Morphological Features, NER and dependencies compared against morphologically-labeled test sets. In all cases, we use raw space-delimited tokens as input and produce morphological segments with our morphological extraction model.</p><p>Table <ref type="table" coords="7,348.09,499.29,5.56,9.46">5</ref> presents evaluation results for the SPRML dataset, compared against the previous SOTA of <ref type="bibr" coords="7,350.78,526.39,82.40,9.46" target="#b14">More et al. (2019)</ref>. For segmentation, POS tagging, and morphological tagging we report aligned multiset F1 scores. BERT-based segmentations are similar, all scoring in the high range of 97-98 F1, which are hard to improve further. <ref type="foot" coords="7,500.64,578.54,7.97,6.91" target="#foot_9">10</ref>For POS tagging and morphological features, all BERT-based models considerably outperform the previous SOTA. For syntactic dependencies we report labeled and unlabeled accuracy scores of the trees generated by YAP <ref type="bibr" coords="7,411.54,649.37,82.16,9.46" target="#b14">(More et al., 2019)</ref> on our predicted segmentation. Here we see impressive improvement compared to the previous SOTA of a joint morpho-syntactic framework. It confirms that morphological errors early in the pipeline negatively impact downstream tasks, and highlight the importance of morphologically-driven benchmarks  <ref type="bibr" coords="8,204.79,312.08,84.70,8.64;8,70.53,324.03,27.09,8.64" target="#b3">Bareket and Tsarfaty (2020)</ref> for the Pipeline (Oracle), Pipeline (Predicted) and a Hybrid (almost-joint) scenarios, respectively.</p><p>as an integral part of PLM evaluation for MRLs.</p><p>All in all we see a repeating trend placing AlephBERT base first on all morphological tasks, indicating the depth of the model and a larger pretraining dataset improve the ability of the PLM to capture word-internal structure. These trends are replicated on the UD Hebrew corpus, for two different evaluation metrics -the Aligned MultiSet F1 Scores as in previous work on Hebrew <ref type="bibr" coords="8,237.72,466.74,52.78,9.46;8,70.86,480.29,23.01,9.46" target="#b14">(More et al., 2019)</ref>, <ref type="bibr" coords="8,101.15,480.29,112.43,9.46" target="#b25">(Seker and Tsarfaty, 2020)</ref>, and the Aligned Segment F1 scores metrics as described in the UD shared task <ref type="bibr" coords="8,125.88,507.39,94.30,9.46" target="#b32">(Zeman et al., 2018)</ref> -reported in Tables <ref type="table" coords="8,101.46,520.94,5.45,9.46">6</ref> and <ref type="table" coords="8,128.12,520.94,5.45,9.46">7</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="8,70.86,544.78,144.49,9.81">Morpheme-Level NER results</head><p>Earlier in this section we considered NER a word-level task that simply requires fine-tuning on the word level. However, this setup is not accurate enough and less useful for downstream tasks, since the exact entity boundaries are often word internal <ref type="bibr" coords="8,231.20,612.95,57.94,9.46;8,70.52,626.50,64.06,9.46" target="#b3">(Bareket and Tsarfaty, 2020)</ref>. We hence report morpheme-based NER evaluation, respecting the exact boundaries of entity mentions.</p><p>To obtain morpheme-based labeled-span of Named Entities, we could either employ a pipeline, first predicting segmentation and then applying a fine-tuned labeling model directly on the segments, or employ a multi-task model and predict NER labels while performing segmentation.</p><p>Table <ref type="table" coords="8,111.70,750.39,5.56,9.46" target="#tab_5">8</ref> presents segmentation and NER results for 3 different scenarios: (i) a pipeline as-suming gold segmentation (ii) a pipeline assuming predicted segmentation (iii) segmentation and NER labels obtained jointly in a multi-task setup. AlephBERT base consistently scores highest in all 3.</p><p>Looking at the Pipeline-Predicted scores, there is a clear correlation between a higher segmentation quality of a PLM and its ability to produce better NER results. Moreover, the differences in NER scores are considerable (unlike the subtle differences in segmentation, POS and morphological features scores) and draw our attention to the relationship between the size of the PLM, the size of the pre-training data and the quality of the final NER models. Specifically, HeBERT and AlephBERT small were both pre-trained on similar datasets and comparable vocabulary sizes (heBERT with 30K and AlephBERT-small with 52K) but HeBERT, with its 12 hidden layers, performs better compared to AlephBERT small which is composed of only 6 hidden layers. It thus appears that semantic information is learned in those deeper layers, helping in both discriminating entities and improving the morphological segmentation capacity.</p><p>In addition, comparing AlephBERT base and HeBERT we note that they are both modeled with the same 12 hidden layer architecture -the only differences between them are in the size of their vocabularies (30K vs 52K respectively) and the size of the training data (Oscar-Wikipedia vs Oscar-Wikipedia-Tweets). The improvements exhibited by AlephBERT base , compared to HeBERT, suggest large amounts of training data and larger vocabulary are invaluable. By exposing AlephBERT base to a substantially larger amount of text we increased the ability of the PLM to encode syntactic and semantic signals associated with Named Entities.</p><p>Our NER experiments further suggest that a pipeline composed of our accurate morphological segmentation model followed by AlephBERT base with a token classification head is the best strategy for generating morphologically-aware NER labels. Finally, we observe that while AlephBERT excels at morphosyntactic tasks, on tasks with a more semantic flavor there is room for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7" coords="8,306.14,685.54,75.07,10.75">Conclusion</head><p>Modern Hebrew, a morphologically-rich and medium-resourced language, has for long suffered from a gap in the resources available for NLP applications, and lower level of empirical results than observed in other, resource-rich languages. This work provides the first step in remedying the situation, by making available a large Hebrew PLM, named AlephBERT, with larger vocabulary and larger training set than any Hebrew PLM before, and with clear evidence as to its empirical advantages. Crucially, we augment the PLM with a morphological disambiguation component that matches the input granularity of the downstream tasks. Our system does not presuppose Hebrewspecific linguistic-rules, and can be transparently applied to any language for which 2-level segmentation data (i.e., the standard UD benchmarks) exists. AlephBERT base obtains state-of-the-art results on morphological segmentation, POS tagging, morphological feature extraction, dependency parsing, named-entity recognition, and sentiment analysis, outperforming all existing Hebrew PLMs. Our proposed morphologically-driven pipeline<ref type="foot" coords="9,239.25,303.01,7.97,6.91" target="#foot_10">foot_10</ref> serves as a solid foundation for future evaluation of Hebrew PLMs and of MRLs in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8" coords="9,70.86,356.88,109.25,10.75">Ethical Statement</head><p>We follow <ref type="bibr" coords="9,118.32,380.45,126.46,9.46" target="#b5">Bender and Friedman (2018)</ref> regarding professional practice for NLP technology and address ethical issues that result from the use of data in the development of the models in our work.</p><p>Pre-Training Data. The two initial data sources we used to pre-train the language models are Oscar and Wikipedia. In using the Wikipedia and Oscar we followed standard language model training efforts, such as BERT and RoBERTa <ref type="bibr" coords="9,255.41,498.32,33.73,9.46;9,70.86,511.87,50.67,9.46" target="#b8">(Devlin et al., 2019;</ref><ref type="bibr" coords="9,124.25,511.87,66.93,9.46" target="#b12">Liu et al., 2019)</ref>. We use the languagespecific Oscar data according to the terms specified in Ortiz Suárez et al. ( <ref type="formula" coords="9,171.98,538.97,19.78,9.46">2020</ref>) and we extract texts from language-specific Wikipedia dumps. On top of that, a big portion of the data used to train Aleph-BERT originates from the Twitter sample stream.<ref type="foot" coords="9,280.67,577.58,7.97,6.91" target="#foot_11">foot_11</ref> As shown in Table <ref type="table" coords="9,157.08,593.17,4.17,9.46" target="#tab_1">2</ref>, this data set includes 70M Hebrew tweets which were collected over a period of 4 years (2014 to 2018). We acknowledge the potential concerns inherently associated with Twitter data (population bias, behavior patterns, bot masquerading as humans etc.) and note that we have not made any explicit attempt to identify these cases. We only used the text field of the tweets and completely discard any other information included in the stream (such as identities, followers, structure of threads, date of publication, etc). We have not made any effort to identify or filter out any samples based on user properties such as age, gender and location nor have we made any effort to identify content characteristics such as genre or topic. To reduce exposure of private information we cleaned up all user mentions and URLs from the text. Honoring ethical and legal constraints we have not manually analyzed nor published this data source. While the free-form language expressed in tweets might differ significantly from the text found in Oscar/Wikipedia, the sheer volume of tweets helps us close the substantial resource gap.</p><p>Training and Evaluation Benchmarks. The SPMRL <ref type="bibr" coords="9,343.69,285.92,88.26,9.46" target="#b24">(Seddah et al., 2013)</ref> and UD <ref type="bibr" coords="9,470.32,285.92,55.47,9.46;9,306.14,299.47,24.94,9.46" target="#b22">(Sadde et al., 2018)</ref> datasets we used for evaluating segmentation, tagging and parsing, were used to both train our morphological extraction model as well as provide us with the test data to evaluate on morphological level tasks. Both datasets are publicly available and widely used in research and industry.</p><p>The NEMO corpus <ref type="bibr" coords="9,401.77,380.95,118.39,9.46" target="#b3">(Bareket and Tsarfaty, 2020</ref>) used to train and evaluate word and morpheme level NER is an extension of the SPMRL dataset augmented with entities and follows the same license terms. The BMC dataset used for training and evaluating word-level NER was created and published by <ref type="bibr" coords="9,367.83,462.25,157.33,9.46" target="#b4">Ben Mordecai and Elhadad (2005)</ref> and it is publicly available for NER evaluation.</p><p>We used the sentiment analysis dataset of <ref type="bibr" coords="9,505.84,489.52,13.60,9.46;9,306.14,503.07,75.20,9.46" target="#b0">Amram et al. (2018)</ref> for training and evaluating Ale-phBERT on a sentence level task, and we follow their terms of use. As mentioned, this dataset had some flows, and we describe carefully the steps we've taken to fix them before using this corpus in our experiments for internal evaluation purposes. We make our in-house cleaning scripts and split information publicly available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,513.97,255.10,12.27,9.46;2,306.14,268.65,220.09,9.46;2,305.75,282.20,218.67,9.46;2,306.14,295.75,218.28,9.46;2,306.14,309.30,219.80,9.46;2,306.14,322.85,220.09,9.46;2,306.14,336.40,218.28,9.46;2,306.14,349.95,218.28,9.46;2,306.14,363.50,218.28,9.46;2,306.14,377.05,218.47,9.46;2,305.78,390.60,218.64,9.46;2,306.14,404.15,218.28,9.46;2,306.14,417.70,218.28,9.46;2,306.14,431.25,220.09,9.46;2,305.87,444.80,218.55,9.46;2,306.14,458.35,220.09,9.46;2,306.14,471.90,218.62,9.46;2,306.14,485.45,218.28,9.46;2,306.14,498.80,218.28,9.66;2,305.84,512.35,218.59,9.65;2,306.14,526.10,88.82,9.46"><figDesc>introduced contextualized word embedding frameworks by training LSTM-based models on massive amounts of texts. The linguistic quality encoded in these models was demonstrated over 6 tasks: Question Answering, Textual Entailment, Semantic Role labeling, Coreference Resolution, Name Entity Extraction, and Sentiment Analysis. The next big leap was obtained with the introduction of the GPT-1 framework by Radford and Sutskever (2018). Instead of using LSTM layers, GPT is based on 12 layers of Transformer decoders with each decoder layer composed of a 768-dimensional feed-forward layer and 12 self-attention heads. Devlin et al. (2019) followed along the same lines and implemented Bidirectional Encoder Representations from Transformers, or BERT in short. BERT attends to the input tokens in both forward and backward directions while optimizing a Masked Language Model and a Next Sentence Prediction objective objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,78.33,73.23,38.60,8.12;5,309.65,73.23,76.37,8.43;5,78.33,85.20,85.96,8.12;5,229.24,85.20,40.58,8.43;5,404.34,85.20,38.88,8.43;5,78.33,98.88,21.17,8.12;5,218.67,98.88,4.68,8.12;5,295.84,98.88,4.68,8.12;5,373.01,98.88,4.68,8.12;5,450.18,98.88,4.68,8.12;5,498.61,98.88,4.68,8.12;5,78.33,110.85,51.34,8.12;5,195.18,110.85,54.11,8.43;5,281.91,110.85,32.53,8.43;5,347.59,110.85,55.53,8.43;5,436.26,110.85,32.53,8.43;5,487.80,110.85,26.29,8.43;5,78.33,122.81,17.17,8.12;5,212.43,122.81,17.16,8.12;5,289.08,122.81,18.20,8.12;5,361.83,122.81,27.03,8.12;5,443.42,122.81,18.20,8.12;5,491.59,122.81,18.72,8.12;5,78.33,134.78,46.80,8.12;5,176.25,135.87,298.43,6.67;5,499.67,135.87,2.56,6.67;5,78.33,146.75,52.50,8.12;5,206.96,146.75,28.08,8.12;5,288.82,146.75,18.72,8.12;5,365.73,146.75,19.25,8.12;5,442.91,146.75,19.24,8.12;5,484.94,146.75,32.01,8.12;5,78.33,158.72,62.57,8.12;5,234.00,158.72,28.60,8.12;5,409.22,158.72,29.12,8.12;5,78.33,170.69,83.08,8.12;5,206.71,170.69,28.60,8.12;5,285.18,170.69,26.00,8.12;5,362.35,170.69,26.00,8.12;5,437.96,170.69,29.12,8.12;5,497.57,170.69,6.76,8.12;5,70.55,192.46,453.87,8.64;5,70.86,204.23,453.57,9.16;5,70.53,216.37,267.76,8.64"><figDesc>Illustration of Evaluated Word-Based and Morpheme-Based Downstream Tasks. The two-word input phrase " ‫הלב‬ ‫,"לבית‬ transliterated as "lbit hlbn" (to the White House), decompose into five morphological segments ('to-the-house the-white'). The Hebrew text goes from right to left.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,70.86,380.62,218.28,8.64;5,70.86,392.58,219.93,8.64;5,70.86,404.53,219.93,8.64;5,97.49,416.49,191.64,8.64;5,70.86,428.45,219.93,8.64;5,70.86,440.40,218.28,8.64;5,70.86,452.36,220.03,8.64;5,70.55,464.31,219.83,8.64;5,70.50,476.27,220.29,8.64;5,70.86,488.22,219.94,8.64;5,70.86,500.18,218.27,8.64;5,70.86,512.14,120.49,8.64;5,71.51,239.17,230.41,129.61"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the Morphological Extraction Model. The embedded vectors associated with the wordpieces (v1 and v2 representing word-piece vectors gen-in Figure1) are combined (averaged) to produce a single word context vector. This context vector initializes the hidden (forward and backward) state of a BiLSTM that encodes the characters of the origin word. The decoder LSTM outputs a sequence of characters, where a special empty symbol indicates a morphological segment boundary. In multi-task setup, a fully connected linear layer is used to predict a label whenever a segment boundary is detected.</figDesc><graphic coords="5,71.51,239.17,230.41,129.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,305.84,73.25,218.94,116.60"><head>Table 1 :</head><label>1</label><figDesc>Corpora Size Comparison: Resource-savvy languages vs. Hebrew.</figDesc><table coords="3,313.68,73.25,203.22,82.27"><row><cell cols="3">Language Oscar (duped) Size Wikipedia Articles</cell></row><row><cell>English</cell><cell>2.3T</cell><cell>6,282,774</cell></row><row><cell>Russian</cell><cell>1.2T</cell><cell>1,713,164</cell></row><row><cell>Chinese</cell><cell>508G</cell><cell>1,188,715</cell></row><row><cell>French</cell><cell>282G</cell><cell>2,316,002</cell></row><row><cell>Arabic</cell><cell>82G</cell><cell>1,109,879</cell></row><row><cell>Hebrew</cell><cell>20G</cell><cell>292,201</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,305.75,506.49,220.48,266.91"><head>Table 2 :</head><label>2</label><figDesc>AlephBERT's Training Data.3 AlephBERT Pre-TrainingData The PLM termed AlephBERT that we provide herein is trained on a larger dataset and a larger vocabulary than any Hebrew BERT instantiation before. The data we train on is listed in Table2. Concretely, we employ the following datasets for pre-training: (i) Oscar: Deduplicated Hebrew portion extracted from Common Crawl via language classification, filtering and cleaning (Ortiz Suárez</figDesc><table coords="4,78.64,73.33,202.71,60.08"><row><cell>Corpus</cell><cell cols="2">File Size Sentences</cell><cell>Words</cell></row><row><cell>Oscar (deduped)</cell><cell>9.8GB</cell><cell cols="2">20.9M 1,043M</cell></row><row><cell>Twitter</cell><cell>6.9GB</cell><cell>71.5M</cell><cell>774M</cell></row><row><cell>Wikipedia</cell><cell>1.1GB</cell><cell>6.3M</cell><cell>127M</cell></row><row><cell>Total</cell><cell>17.9GB</cell><cell>98.7M</cell><cell>1.9B</cell></row></table><note coords="3,385.82,506.49,138.61,9.46;3,306.14,520.04,220.09,9.46;3,306.14,533.59,218.28,9.46;3,306.14,547.14,220.09,9.46;3,306.14,560.69,219.64,9.46;3,306.14,574.24,218.66,9.46;3,305.75,587.79,220.48,9.46;3,306.14,601.34,218.28,9.46;3,306.14,614.89,218.28,9.46;3,306.14,628.44,218.66,9.46;3,306.14,641.99,218.66,9.46;3,306.14,655.54,218.46,9.46;3,305.75,669.09,218.67,9.46;3,306.14,682.64,218.46,9.46;3,305.75,696.19,218.86,9.46;3,306.14,709.74,218.28,9.46;3,306.14,723.29,218.27,9.46;3,305.75,736.84,218.67,9.46;3,306.14,750.39,218.28,9.46;3,306.14,763.94,193.93,9.46"><p>Non examined the capacity of PLMs to encode sub-word morphological-level information which we focus on in this work.Şahin  et al. (2019)  </p><p>probed various information types encoded in embedded word vectors. Similarly to us, they focused on languages with rich morphology where linguistic signals are encoded at the morphological, subword level. Their work is more about explainability -showing high positive correlation of probing tasks to the downstream tasks, especially for morphologically rich languages. Unlike us, they assume a single POS tag and set of features per word in their probing tasks. In Hebrew, Arabic and other MRLs, tokens may carry multiple POS per word, and are required to be segmented for further processing. We provide a framework that extracts subword morphological units given contextualized word vectors, that enables to evaluate PLMs on morphologically-aware datasets where words can have multiple POS tags and feature-bundles.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,70.55,73.49,218.59,124.04"><head>Table 4 :</head><label>4</label><figDesc>Word-based NER F1. Previous SOTA on both corpora reported by the NEMO models of</figDesc><table coords="7,79.12,73.49,201.74,90.56"><row><cell>Task</cell><cell>NER (Word)</cell><cell>Sentiment</cell></row><row><cell>Corpus</cell><cell>NEMO BMC</cell><cell>FB</cell></row><row><cell>Prev. SOTA</cell><cell>77.75 85.22</cell><cell>NA</cell></row><row><cell>mBERT</cell><cell>79.07 87.77</cell><cell>79.07</cell></row><row><cell>HeBERT</cell><cell>81.48 89.41</cell><cell>81.48</cell></row><row><cell>AlephBERT small</cell><cell>78.69 89.07</cell><cell>78.69</cell></row><row><cell>AlephBERT base</cell><cell>84.91 91.12</cell><cell>84.91</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,70.46,72.87,455.62,700.52"><head>Table 4 .</head><label>4</label><figDesc>All BERTbased models substantially outperform the original CNN Baseline reported by<ref type="bibr" coords="7,195.09,612.44,91.32,9.46" target="#b0">Amram et al. (2018)</ref>. AlephBERT base is setting a new SOTA.</figDesc><table coords="7,70.46,647.11,220.49,91.18"><row><cell>Word-Based Task On our two NER benchmarks,</cell></row><row><cell>we report F1 scores on the word-based fine-tuned</cell></row><row><cell>model in Table 4. While we see noticeable improve-</cell></row><row><cell>ments for the mBERT and HeBert variants over</cell></row><row><cell>the current SOTA, the most significant increase</cell></row><row><cell>is achieved by AlephBERT base , setting a new and</cell></row><row><cell>improved SOTA on this task.</cell></row></table><note coords="7,70.86,749.96,218.66,9.88;7,70.86,763.94,220.09,9.46"><p>Morpheme-Level Tasks As a particular novelty of this work, we report BERT-based results on sub-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,70.55,73.39,220.24,247.32"><head>Table 8 :</head><label>8</label><figDesc>Morpheme-Based NER F1 on the NEMO corpus. Previous SOTA reported by</figDesc><table coords="8,70.55,73.39,218.93,214.12"><row><cell>Task</cell><cell></cell><cell cols="5">Segment POS Features</cell></row><row><cell cols="2">Prev. SOTA</cell><cell>96.03</cell><cell cols="2">93.75</cell><cell>91.24</cell><cell></cell></row><row><cell cols="2">mBERT</cell><cell>97.17</cell><cell cols="2">94.27</cell><cell>90.51</cell><cell></cell></row><row><cell cols="2">HeBERT</cell><cell>97.54</cell><cell cols="2">95.60</cell><cell>92.15</cell><cell></cell></row><row><cell cols="2">AlephBERT small</cell><cell>97.31</cell><cell cols="2">95.13</cell><cell>91.65</cell><cell></cell></row><row><cell cols="2">AlephBERT base</cell><cell>97.70</cell><cell cols="2">95.84</cell><cell>92.71</cell><cell></cell></row><row><cell cols="7">Table 7: Morpheme-Based Aligned (CoNLL shared</cell></row><row><cell cols="7">task) F1 on the UD corpus. Previous SOTA reported by</cell></row><row><cell cols="5">Minh Van Nguyen and Nguyen (2021)</cell><cell></cell><cell></cell></row><row><cell>Architecture</cell><cell cols="2">Pipeline</cell><cell cols="2">Pipeline</cell><cell cols="2">MultiTask</cell></row><row><cell>Segmentation</cell><cell cols="2">(Oracle)</cell><cell cols="2">(Predicted)</cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell>Seg</cell><cell>NER</cell><cell>Seg</cell><cell>NER</cell><cell>Seg</cell><cell>NER</cell></row><row><cell cols="7">Prev. SOTA 100.00 79.10 95.15 69.52 97.05 77.11</cell></row><row><cell cols="7">mBERT 100.00 77.92 97.68 72.72 97.24 72.97</cell></row><row><cell cols="2">HeBERT 100.00</cell><cell>82</cell><cell cols="4">98.15 76.74 97.92 74.86</cell></row><row><cell cols="7">AlephBERT small 100.00 79.44 97.78 73.08 97.74 72.46</cell></row><row><cell cols="7">AlephBERT base 83.94 98.29 80.15 98.19 79.15</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,322.28,745.28,202.14,7.77;1,306.14,755.08,219.40,7.94"><p>These morphemes are affixes and clitics bearing their own POS. They are termed syntactic words in UD(Zeman et al.,   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="1,306.14,765.04,206.39,7.94"><p>2018), or segments in previous literature on Hebrew NLP.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="2,87.00,735.31,203.21,7.77;2,70.86,745.28,222.04,7.77;2,70.86,755.24,219.40,7.77;2,70.86,765.20,201.64,7.77"><p>We make our PLM https://huggingface.co/ onlplab/alephbert-base and demo https://nlp. biu.ac.il/~amitse/alephbert/ publicly available, to qualitatively assess present and future Hebrew PLMs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,322.28,745.28,203.63,7.77;5,306.14,755.24,219.35,7.77;5,306.14,766.04,113.98,6.31"><p>This version has a total of 8,465 samples and is publicly available here: https://github.com/OnlpLab/ Hebrew-Sentiment-Data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,87.00,713.77,203.21,7.77;6,70.86,724.58,59.68,6.31"><p>Available here: https://github.com/OnlpLab/ NEMO-Corpus</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,87.00,735.43,193.68,6.31;6,70.86,745.39,139.88,6.31"><p>https://universaldependencies.org/u/ overview/tokenization.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,87.00,756.08,182.92,6.31;6,70.86,766.04,151.15,6.31"><p>https://universaldependencies.org/ conll18/results-alltags.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,322.28,735.27,182.92,6.31;6,306.14,745.23,107.60,6.31"><p>https://universaldependencies.org/ conll18/results.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="6,322.28,755.24,202.14,7.77;6,305.25,765.20,151.73,7.77"><p>respectively referred to as 'Segmented Words' and 'UPOS' in the CoNLL18 evaluation script</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="7,322.28,755.24,203.62,7.77;7,306.14,765.20,146.44,7.77"><p>According to error analysis, most of these errors are annotation errors or truly ambiguous cases.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="9,87.00,724.46,203.21,7.77;9,70.59,735.27,48.42,6.31"><p>Available at https://github.com/OnlpLab/ AlephBERT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11" coords="9,87.00,746.12,177.54,6.31;9,70.86,756.08,210.82,6.31;9,70.86,766.04,206.43,6.31"><p>https://developer.twitter.com/en/ docs/twitter-api/tweets/volume-streams/ api-reference/get-tweets-sample-stream</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head coords="9,306.14,621.15,98.84,10.75">Acknowledgements</head><p>This research was funded by the <rs type="funder">European Research Council</rs> (<rs type="grantName">ERC</rs> grant agreement no. <rs type="grantNumber">677352</rs>) and by a research grant from the <rs type="funder">Ministry of Science and Technology (MOST) of the Israeli Government</rs>, for which we are grateful.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_yvASUxQ">
					<idno type="grant-number">677352</idno>
					<orgName type="grant-name">ERC</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,306.14,753.59,220.02,8.64;9,317.05,764.55,209.02,8.64;10,81.77,75.32,209.02,8.64;10,81.77,86.10,209.02,8.82;10,81.77,97.06,207.37,8.59;10,81.44,108.02,209.44,8.59;10,81.44,118.98,209.19,8.82;10,81.77,130.12,22.42,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main">Representations and architectures in neu-ral sentiment analysis for morphologically rich languages: A case study from modern hebrew</title>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Amram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anat</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018</title>
		<meeting>the 27th International Conference on Computational Linguistics, COLING 2018<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08-20">2018. August 20-26, 2018</date>
			<biblScope unit="page" from="2242" to="2252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,151.90,220.02,8.64;10,81.41,162.86,209.38,8.64;10,81.77,173.64,209.02,8.82;10,81.77,184.60,209.02,8.59;10,81.77,195.56,207.36,8.59;10,81.41,206.52,207.73,8.82;10,81.77,217.66,130.87,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main">AraBERT: Transformer-based model for Arabic language understanding</title>
		<author>
			<persName coords=""><forename type="first">Fady</forename><surname>Wissam Antoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hazem</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hajj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</title>
		<meeting>the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resource Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,239.44,219.47,8.64;10,81.77,251.34,193.78,7.01" xml:id="b2">
	<analytic>
		<title level="a" type="main">Attardi, Ugo</title>
		<author>
			<persName coords=""><forename type="first">Giusepppe</forename><surname>Attardi</surname></persName>
		</author>
		<idno type="DOI">10.1093/benz/9780199773787.article.b00008286</idno>
		<ptr target="https://github.com/attardi/wikiextractor" />
	</analytic>
	<monogr>
		<title level="m">Wikiextractor</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,272.18,218.27,8.64;10,81.77,282.97,208.61,8.82;10,81.77,294.10,65.87,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural Modeling for Named Entities and Morphology (NEMO2)</title>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Bareket</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00404</idno>
		<idno>CoRR, abs/2007.15620</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<idno type="ISSNe">2307-387X</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="909" to="928" />
			<date type="published" when="2020">2020</date>
			<publisher>MIT Press - Journals</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,315.89,219.93,8.64;10,81.77,326.85,124.27,8.64" xml:id="b4">
	<monogr>
		<title level="m" type="main">Hebrew named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">Naama</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mordecai</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,348.63,218.28,8.64;10,81.77,359.59,207.37,8.64;10,81.77,370.55,209.11,8.64;10,81.21,381.33,207.92,8.59;10,81.49,392.29,93.83,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main">Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</title>
		<author>
			<persName coords=""><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Batya</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00041</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<title level="j" type="abbrev">TACL</title>
		<idno type="ISSNe">2307-387X</idno>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2018-12">2018</date>
			<publisher>MIT Press - Journals</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,414.25,218.28,8.64;10,81.77,425.21,207.36,8.64;10,81.77,436.17,207.36,8.64;10,81.41,447.13,208.97,8.64;10,81.77,458.09,208.61,8.64;10,81.41,469.05,207.73,8.64;10,81.30,480.01,209.49,8.64;10,81.77,490.97,207.62,8.64;10,81.77,501.93,207.37,8.64;10,81.77,512.89,209.11,8.64;10,81.77,523.67,209.02,8.82;10,81.77,534.63,208.61,8.59;10,81.52,545.77,126.69,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,212.18,545.77,78.20,8.64;10,81.77,556.73,15.21,8.64;10,70.86,578.51,219.06,8.64;10,81.77,589.47,207.71,8.64;10,81.77,600.43,134.49,8.64" xml:id="b7">
	<monogr>
		<title level="m" type="main">Hebert |&amp; hebemo: a hebrew bert model and a tool for polarity analysis and emotion recognition</title>
		<author>
			<persName coords=""><forename type="first">Inc</forename><forename type="middle">Avihay</forename><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Inbal</forename><surname>Chriqui</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yahav</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,70.86,622.21,218.28,8.64;10,81.77,633.17,207.37,8.64;10,81.77,644.13,209.03,8.64;10,81.77,654.91,207.37,8.82;10,81.77,665.87,207.37,8.59;10,81.44,676.83,209.36,8.59;10,81.77,687.79,207.36,8.82;10,81.42,698.93,207.88,8.64;10,81.77,709.89,108.50,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main"></title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North</title>
		<meeting>the 2019 Conference of the North<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="10,70.86,731.67,218.28,8.64;10,81.77,742.63,209.02,8.64;10,81.77,753.59,207.36,8.64;10,81.77,764.55,58.94,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main">ParsBERT: Transformer-based Model for Persian Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Mehrdad</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marzieh</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><surname>Manthouri</surname></persName>
			<idno type="ORCID">0000-0003-3461-9250</idno>
		</author>
		<idno type="DOI">10.1007/s11063-021-10528-4</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<title level="j" type="abbrev">Neural Process Lett</title>
		<idno type="ISSN">1370-4621</idno>
		<idno type="ISSNe">1573-773X</idno>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3831" to="3847" />
			<date type="published" when="2020">2020</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,75.32,218.27,8.64;10,317.05,86.28,209.11,8.64;10,317.05,97.06,207.37,8.82;10,316.45,108.02,209.63,8.59;10,316.77,118.98,209.40,8.82;10,316.69,130.12,172.14,8.64" xml:id="b10">
	<analytic>
		<title level="a" type="main">Universal Language Model Fine-tuning for Text Classification</title>
		<author>
			<persName coords=""><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p18-1031</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
	<note>: Long Papers)</note>
</biblStruct>

<biblStruct coords="10,306.14,150.68,218.28,8.64;10,317.05,161.64,209.02,8.64;10,317.05,172.42,207.37,8.82;10,316.31,183.38,208.12,8.59;10,316.74,194.34,209.42,8.59;10,316.80,205.30,207.62,8.82;10,317.05,216.44,37.36,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main">Getting the ##life out of living: How Adequate Are Word-Pieces for Modelling Complex Morphology?</title>
		<author>
			<persName coords=""><forename type="first">Stav</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.sigmorphon-1.24</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
		<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>SIGMORPHON</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-10">2020. 2020. July 10, 2020</date>
			<biblScope unit="page" from="204" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,237.01,219.93,8.64;10,317.05,247.97,208.61,8.64;10,317.05,258.93,209.11,8.64;10,317.05,269.88,209.02,8.64;10,317.05,280.84,57.00,8.64" xml:id="b12">
	<monogr>
		<title level="m" type="main">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,301.41,218.27,8.64;10,317.05,312.37,209.02,8.64;10,316.69,323.33,209.39,8.64;10,317.05,334.11,207.37,8.82;10,316.72,345.07,209.35,8.59;10,317.05,356.03,209.02,8.59;10,317.05,366.99,37.22,8.59" xml:id="b13">
	<analytic>
		<title level="a" type="main">Trankit: A lightweight transformer-based toolkit for multilingual natural language processing</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Amir Pouran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Viet</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thien</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Huu Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,387.73,218.28,8.64;10,316.74,398.69,207.85,8.64;10,317.05,409.65,207.37,8.64;10,317.05,420.43,209.11,8.82;10,316.72,431.39,120.40,8.82" xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint transition-based models for morpho-syntactic parsing: Parsing strategies for mrls and a case study from modern hebrew</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Amir More</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victoria</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Basmova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,452.14,218.28,8.64;10,317.05,463.10,209.02,8.64;10,317.05,474.06,209.11,8.64;10,317.05,484.84,209.03,8.82;10,317.05,495.80,208.86,8.82;10,316.31,506.94,209.77,8.64;10,317.05,517.90,16.33,8.64" xml:id="b15">
	<analytic>
		<title level="a" type="main">A monolingual approach to contextualized word embeddings for mid-resource languages</title>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><surname>Javier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ortiz</forename><surname>Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1703" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,538.46,218.28,8.64;10,317.05,549.42,207.37,8.64;10,317.05,560.38,209.02,8.64;10,317.05,571.16,207.37,8.82;10,317.05,582.12,207.37,8.59;10,316.72,593.08,209.36,8.59;10,317.05,604.04,208.61,8.82;10,317.05,615.18,209.02,8.64;10,317.05,626.14,71.96,8.64" xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep Contextualized Word Representations</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="10,306.14,646.70,219.52,8.64;10,317.05,657.66,209.02,8.64;10,317.05,668.62,207.53,8.64;10,317.05,679.58,152.20,8.64" xml:id="b17">
	<analytic>
		<title level="a" type="main">AlBERTo: Modeling Italian Social Media Language with BERT</title>
		<author>
			<persName coords=""><forename type="first">Marco</forename><surname>Polignano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierpaolo</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>De gemmis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Semeraro</surname></persName>
		</author>
		<idno type="DOI">10.4000/ijcol.472</idno>
	</analytic>
	<monogr>
		<title level="j">Italian Journal of Computational Linguistics</title>
		<title level="j" type="abbrev">ijcol</title>
		<idno type="ISSNe">2499-4553</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="11" to="31" />
			<date type="published" when="2019-12-01">2019</date>
			<publisher>OpenEdition</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,306.14,700.15,218.28,8.64;10,317.05,711.11,209.11,8.64;10,317.05,721.89,33.75,8.82" xml:id="b18">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName coords=""><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arxiv</note>
</biblStruct>

<biblStruct coords="10,306.14,742.63,219.93,8.64;10,317.05,753.59,207.37,8.64;10,317.05,764.55,207.37,8.64;11,81.77,75.32,207.37,8.64;11,81.77,86.10,208.61,8.82;11,81.77,97.24,56.73,8.64" xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,118.86,218.27,8.64;11,81.77,129.82,207.54,8.64;11,81.77,140.60,207.37,8.82;11,81.77,151.56,209.02,8.59;11,81.77,162.52,208.62,8.82;11,81.46,173.66,200.07,8.64" xml:id="b20">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ Questions for Machine Comprehension of Text</title>
		<author>
			<persName coords=""><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,195.28,218.28,8.64;11,81.77,206.24,207.37,8.64;11,81.77,217.20,207.37,8.64;11,81.46,227.98,209.34,8.59;11,81.77,238.94,208.86,8.82;11,81.02,250.08,209.77,8.64;11,81.77,261.04,16.33,8.64" xml:id="b21">
	<analytic>
		<title level="a" type="main">KLEJ: Comprehensive Benchmark for Polish Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Rybak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Mroczkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janusz</forename><surname>Tracz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ireneusz</forename><surname>Gawlik</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.111</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1191" to="1201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,282.66,220.03,8.64;11,81.77,293.62,209.02,8.64;11,81.77,304.40,207.37,8.82;11,81.77,315.36,209.11,8.59;11,81.41,326.32,207.73,8.59;11,81.02,337.28,97.41,8.82" xml:id="b22">
	<analytic>
		<title level="a" type="main">The Hebrew Universal Dependency Treebank: Past Present and Future</title>
		<author>
			<persName><forename type="first">Shoval</forename><surname>Sade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w18-6016</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Universal Dependencies (UDW 2018)</title>
		<meeting>the Second Workshop on Universal Dependencies (UDW 2018)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-01">2018. November 1, 2018</date>
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,359.09,218.28,8.64;11,81.77,370.05,209.02,8.64;11,81.77,380.83,208.61,8.82;11,81.77,391.96,65.87,8.64" xml:id="b23">
	<monogr>
		<title level="m" type="main">LINSPECTOR: multilingual probing tasks for word representations</title>
		<author>
			<persName coords=""><forename type="first">Gözde</forename><surname>Gül Şahin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clara</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilia</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno>CoRR, abs/1903.09442</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,413.59,218.28,8.64;11,81.77,424.55,207.53,8.64;11,81.77,435.51,209.02,8.64;11,81.77,446.47,208.61,8.64;11,81.77,457.43,208.61,8.64;11,81.41,468.39,208.97,8.64;11,81.19,479.35,209.60,8.64;11,81.77,491.45,207.37,8.64;11,81.77,502.41,207.37,8.64;11,81.77,513.37,209.02,8.64;11,81.77,524.15,209.02,8.82;11,81.77,535.11,207.37,8.59;11,81.35,546.07,207.78,8.59;11,81.52,557.03,208.86,8.59;11,81.77,568.17,62.54,8.64" xml:id="b24">
	<analytic>
		<title level="a" type="main">Overview of the SPMRL 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages</title>
		<author>
			<persName coords=""><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iakes</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koldo</forename><surname>Gojenola Galletebeitia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Przepiórkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Woliński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Wróblewska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Villemonte De La Clergerie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w13-4917</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages</title>
		<meeting>the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10-18">2013. October 18, 2013</date>
			<biblScope unit="page" from="146" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,589.79,219.93,8.64;11,81.41,600.75,209.38,8.64;11,81.77,611.53,207.37,8.82;11,81.77,622.49,207.36,8.82;11,81.42,633.63,207.72,8.64;11,81.77,644.59,46.78,8.64" xml:id="b25">
	<analytic>
		<title level="a" type="main">A Pointer Network Architecture for Joint Morphological Segmentation and Tagging</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.391</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4368" to="4378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.86,666.21,220.02,8.64;11,81.77,677.17,207.36,8.64;11,81.77,687.95,207.37,8.82;11,81.35,698.91,209.44,8.59;11,81.77,709.87,208.62,8.82;11,81.77,721.01,209.02,8.64;11,81.77,731.97,32.94,8.64" xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName coords=""><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p16-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>: Long Papers)</note>
</biblStruct>

<biblStruct coords="11,70.86,753.59,220.02,8.64;11,81.77,764.55,207.37,8.64;11,316.72,75.32,209.36,8.64;11,317.05,86.10,207.37,8.82;11,316.45,97.06,209.63,8.59;11,317.05,108.02,208.61,8.59;11,317.05,119.16,72.50,8.64" xml:id="b27">
	<analytic>
		<title level="a" type="main">From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)?</title>
		<author>
			<persName coords=""><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Bareket</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stav</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.660</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="7396" to="7408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,306.14,139.08,219.53,8.64;11,316.86,150.04,207.56,8.64;11,317.05,161.00,208.76,8.64;11,317.05,171.96,63.38,8.64" xml:id="b28">
	<monogr>
		<title level="m" type="main">Multilingual is not enough: Bert for finnish</title>
		<author>
			<persName coords=""><forename type="first">Antti</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rami</forename><surname>Ilo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jouni</forename><surname>Luoma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,306.14,191.89,218.53,8.64;11,317.05,202.85,208.75,8.64;11,316.69,213.81,209.39,8.64;11,317.05,224.59,207.37,8.82;11,316.80,235.55,207.62,8.59;11,317.05,246.51,207.37,8.82;11,317.05,257.65,209.02,8.64;11,317.05,268.60,89.12,8.64" xml:id="b29">
	<analytic>
		<title level="a" type="main">GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w18-5446</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,306.14,288.53,218.28,8.64;11,317.05,299.49,209.03,8.64;11,317.05,310.45,208.62,8.64;11,316.86,321.41,207.56,8.64;11,317.05,332.37,207.36,8.64;11,317.05,343.33,207.37,8.64;11,317.05,354.29,209.02,8.64;11,317.05,365.25,207.37,8.64;11,316.74,376.03,207.68,8.59;11,316.64,386.99,207.79,8.59;11,316.69,397.95,207.73,8.82;11,317.05,409.08,122.61,8.64" xml:id="b30">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,306.14,429.01,218.28,8.64;11,317.05,439.97,207.37,8.64;11,317.05,450.75,209.02,8.82;11,317.05,461.71,207.36,8.59;11,316.72,472.67,209.35,8.82;11,317.05,483.81,209.02,8.64;11,317.05,494.77,32.94,8.64" xml:id="b31">
	<analytic>
		<title level="a" type="main">SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</title>
		<author>
			<persName coords=""><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,306.14,514.69,219.52,8.64;11,317.05,525.65,207.62,8.64;11,317.05,536.61,207.37,8.64;11,317.05,547.57,207.36,8.64;11,316.74,558.35,209.34,8.59;11,317.05,569.31,209.02,8.59;11,317.05,580.27,207.37,8.82;11,317.05,591.41,122.61,8.64" xml:id="b32">
	<analytic>
		<title level="a" type="main">CoNLL 2018 shared task: Multilingual parsing from raw text to Universal Dependencies</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Daniel Zeman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Milan</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Filip</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joakim</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Slav</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-2001</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
